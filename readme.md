# ğŸ›¡ï¸ A Predictive Approach to XSS Detection Using ML Algorithms

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13%2B-orange.svg)](https://www.tensorflow.org/)
[![Flask](https://img.shields.io/badge/Flask-2.3%2B-green.svg)](https://flask.palletsprojects.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Ongoing-red.svg)]()

> **Note**: This project is currently under active development. Features and documentation are being continuously updated.

An intelligent Cross-Site Scripting (XSS) detection and prevention system powered by a hybrid CNN-LSTM deep learning architecture. This system provides real-time detection of malicious XSS payloads with 98%+ accuracy, offering robust protection against both standard and obfuscated attacks.

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Architecture](#architecture)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Training the Model](#training-the-model)
- [Running the Server](#running-the-server)
- [Using the Web Interface](#using-the-web-interface)
- [API Usage](#api-usage)
- [Testing Examples](#testing-examples)
- [Project Structure](#project-structure)
- [Model Performance](#model-performance)
- [Troubleshooting](#troubleshooting)
- [Contributing](#contributing)
- [Roadmap](#roadmap)
- [License](#license)

## ğŸ¯ Overview

Cross-Site Scripting (XSS) remains one of the most prevalent web security vulnerabilities. Traditional rule-based detection systems struggle with:
- Encoded and obfuscated payloads
- Novel attack vectors
- Context-aware attacks
- High false positive rates

Our solution leverages a **CNN-LSTM hybrid neural network** that:
- âœ… Learns patterns automatically from data
- âœ… Detects obfuscated and encoded attacks
- âœ… Adapts to new attack vectors through retraining
- âœ… Provides real-time detection with millisecond latency
- âœ… Achieves 98%+ accuracy with low false positive rate

### Why CNN-LSTM?

- **CNN (Convolutional Neural Network)**: Extracts local patterns like `<script>`, `onerror=`, `alert(`
- **LSTM (Long Short-Term Memory)**: Understands sequential context and relationships between patterns
- **Hybrid Approach**: Combines spatial pattern recognition with temporal sequence understanding

## âœ¨ Features

### Core Capabilities
- ğŸ¯ **Real-time XSS Detection**: Sub-20ms inference time
- ğŸ§  **Deep Learning Powered**: CNN-LSTM hybrid architecture
- ğŸ”’ **Input Sanitization**: Automatic cleaning of malicious content
- ğŸŒ **REST API**: Easy integration with any web application
- ğŸ“Š **Detailed Analytics**: Confidence scores and probability breakdown
- ğŸ“ **Request Logging**: Track and analyze malicious attempts
- ğŸ”„ **Batch Processing**: Check multiple inputs simultaneously

### Detection Capabilities
- Standard XSS patterns (`<script>alert(1)</script>`)
- Event handler injections (`<img onerror=alert(1)>`)
- Protocol-based attacks (`javascript:alert(1)`)
- Encoded payloads (URL encoding, HTML entities, Unicode)
- Obfuscated attacks (case mixing, whitespace injection)
- DOM-based XSS patterns
- Framework-specific injections

## ğŸ—ï¸ Architecture

```
User Input â†’ Flask API â†’ Preprocessing â†’ CNN-LSTM Model â†’ Sanitization â†’ Response
                â†“                              â†“
           Validation                    2.1M Parameters
                                        (Character-level)
```

### Model Architecture

```
Input (300 chars)
    â†“
Embedding (256D)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Parallel CNNs      â”‚
â”‚  - Kernel 3, 5, 7   â”‚  â† Pattern Detection
â”‚  - 128 filters each â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Concatenate
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Bidirectional LSTM â”‚  â† Sequence Understanding
â”‚  - 128 units        â”‚
â”‚  - 64 units         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Dense Layers (256â†’128â†’64)
    â†“
Output (Sigmoid)
[0=Safe, 1=Malicious]
```

## ğŸš€ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager
- 4GB RAM minimum (8GB recommended)
- 2GB free disk space

### Step 1: Clone Repository

```bash
git clone https://github.com/IsMohit/A-Predictive-Approach-to-XSS-Detection-Using-ML-Algorithms.git
cd A-Predictive-Approach-to-XSS-Detection-Using-ML-Algorithms
```

### Step 2: Create Virtual Environment

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/Mac:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### Step 3: Install Dependencies

```bash
# Install all required packages
pip install -r requirements_cnn_lstm.txt
```

**Core Dependencies:**
- `tensorflow>=2.13.0` - Deep learning framework
- `scikit-learn>=1.3.0` - Machine learning utilities
- `flask>=2.3.0` - Web server
- `flask-cors>=4.0.0` - CORS support
- `pandas>=2.0.0` - Data manipulation
- `numpy>=1.24.0` - Numerical computing
- `bleach>=6.0.0` - HTML sanitization

## âš¡ Quick Start

### Complete Setup (5 minutes)

```bash
# 1. Activate virtual environment
source venv/bin/activate  # or venv\Scripts\activate on Windows

# 2. Generate training dataset
python generate_dataset.py

# 3. Validate dataset
python validate_dataset.py

# 4. Train the model (takes 3-5 minutes)
python xss_cnn_lstm_trainer.py

# 5. Start the API server
python app_cnn_lstm.py

# 6. Open the web interface
# Open index.html in your browser
```

The API will be available at `http://localhost:5000`

## ğŸ“ Training the Model

### Option 1: Using Generated Dataset

```bash
# Generate a balanced dataset (2000 samples)
python generate_dataset.py
```

This creates `Xss_SafeInput_Dataset.csv` with:
- 15k+ malicious inputs (XSS payloads, obfuscated attacks) & safe inputs (normal text, URLs, emails)

### Option 2: Using Your Own Dataset

**Required Format:** CSV with two columns: `input` and `label`

```csv
input,label
Hello world,0
<script>alert(1)</script>,1
Welcome to our website,0
<img src=x onerror=alert(1)>,1
```

### Training Process

```bash
# Train the CNN-LSTM model
python xss_cnn_lstm_trainer.py
```

**Expected Output:**
```
ğŸ›¡ï¸  ML-Based XSS Detection - Improved CNN-LSTM Model
================================================================================
ğŸ“‚ Loading dataset...
âœ… Loaded 2000 samples
   Safe samples: 1000
   Malicious samples: 1000

ğŸ¤– Training Improved CNN-LSTM Model...
   Training samples: 1600
   Testing samples: 400

ğŸš€ Starting training for 30 epochs...
Epoch 1/30
50/50 [==============================] - 15s 300ms/step
...

âœ¨ Model Performance Metrics:
   Test Accuracy:  0.9993 (99.93%)
   Test Precision: 1.0000 (100.00%)
   Test Recall:  0.9985 (99.85%)
   Test F1-Score:  0.9993

ğŸ’¾ Saving model...
âœ… Training Complete!
```

**Training Time:**
- Small dataset (2K samples): 3-5 minutes
- Medium dataset (10K samples): 15-20 minutes
- Large dataset (50K samples): 1-2 hours

**Output Files:**
- `xss_cnn_lstm_model.h5` - Trained model (~80-100 MB)
- `tokenizer.pkl` - Character tokenizer (~1-5 MB)
- `xss_cnn_lstm_best.h5` - Best model checkpoint

## ğŸŒ Running the Server

### Development Server

```bash
# Start Flask development server
python app_cnn_lstm.py
```

**Output:**
```
ğŸ›¡ï¸  ML-Based XSS Detection API Server (CNN-LSTM)
================================================================================
ğŸ“¥ Loading CNN-LSTM model...
âœ… CNN-LSTM model loaded successfully!

ğŸš€ Starting Flask server...
ğŸ“¡ API will be available at: http://localhost:5000

 * Running on http://0.0.0.0:5000
 * Debug mode: on
```

### Production Server

```bash
# Install gunicorn
pip install gunicorn

# Run with gunicorn (production-ready)
gunicorn -w 4 -b 0.0.0.0:5000 --timeout 120 app_cnn_lstm:app
```

**Server Configuration:**
- Workers: 4 (adjust based on CPU cores)
- Timeout: 120 seconds (for model loading)
- Host: 0.0.0.0 (accessible from all interfaces)
- Port: 5000

## ğŸ–¥ï¸ Using the Web Interface

### Opening the Interface

1. **Start the API server** (see above)
2. **Open `index.html`** in your web browser
3. **Enter text** in the input field
4. **Click "Check for XSS"**


### Interface Sections

1. **Input Area**: Enter or paste text to check
2. **Action Buttons**: 
   - ğŸ” Check for XSS
   - ğŸ—‘ï¸ Clear input
3. **Results Display**:
   - Prediction (Safe/Malicious)
   - Confidence percentage
   - Probability breakdown
   - Sanitized output
   - Risk level (for malicious inputs)
4. **Example Buttons**: Quick test cases

## ğŸ“¡ API Usage

### Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | API documentation |
| `/health` | GET | Health check |
| `/check` | POST | Check single input |
| `/batch-check` | POST | Check multiple inputs |
| `/stats` | GET | View statistics |
| `/model-info` | GET | Model information |

### Examples

#### 1. Check Single Input

**Request:**
```bash
curl -X POST http://localhost:5000/check \
  -H "Content-Type: application/json" \
  -d '{"input": "<script>alert(1)</script>"}'
```

**Response:**
```json
{
  "prediction": "malicious",
  "confidence": 98.5,
  "sanitized": "",
  "probabilities": {
    "safe": 1.5,
    "malicious": 98.5
  },
  "warning": "Potential XSS attack detected by CNN-LSTM model!",
  "risk_level": "high",
  "model_used": "CNN-LSTM",
  "timestamp": "2025-10-26T12:00:00Z"
}
```

#### 2. Safe Input

**Request:**
```bash
curl -X POST http://localhost:5000/check \
  -H "Content-Type: application/json" \
  -d '{"input": "Hello, this is a normal comment"}'
```

**Response:**
```json
{
  "prediction": "safe",
  "confidence": 99.2,
  "sanitized": "Hello, this is a normal comment",
  "probabilities": {
    "safe": 99.2,
    "malicious": 0.8
  },
  "model_used": "CNN-LSTM",
  "timestamp": "2025-10-26T12:00:00Z"
}
```

#### 3. Batch Check

**Request:**
```bash
curl -X POST http://localhost:5000/batch-check \
  -H "Content-Type: application/json" \
  -d '{"inputs": ["Hello world", "<script>alert(1)</script>", "<img src=x onerror=alert(1)>"]}'
```

**Response:**
```json
{
  "total": 3,
  "malicious_detected": 2,
  "safe_detected": 1,
  "model_used": "CNN-LSTM",
  "results": [
    {
      "index": 0,
      "prediction": "safe",
      "confidence": 99.1,
      "sanitized": "Hello world"
    },
    {
      "index": 1,
      "prediction": "malicious",
      "confidence": 98.5,
      "sanitized": ""
    },
    {
      "index": 2,
      "prediction": "malicious",
      "confidence": 97.8,
      "sanitized": ""
    }
  ]
}
```

#### 4. Python Integration

```python
import requests

def check_xss(user_input):
    """Check if input contains XSS"""
    response = requests.post(
        'http://localhost:5000/check',
        json={'input': user_input}
    )
    result = response.json()
    
    if result['prediction'] == 'malicious':
        print(f"âš ï¸ XSS Detected! Confidence: {result['confidence']}%")
        return False
    else:
        print(f"âœ… Input is safe. Confidence: {result['confidence']}%")
        return True

# Example usage
user_comment = input("Enter your comment: ")
if check_xss(user_comment):
    # Save comment to database
    save_comment(user_comment)
else:
    print("Comment rejected due to security concerns")
```

#### 5. JavaScript Integration

```javascript
async function validateInput(input) {
    try {
        const response = await fetch('http://localhost:5000/check', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({ input: input })
        });
        
        const data = await response.json();
        
        if (data.prediction === 'malicious') {
            alert(`âš ï¸ XSS Detected! Confidence: ${data.confidence}%`);
            return false;
        }
        
        return true;
    } catch (error) {
        console.error('Validation error:', error);
        return false; // Fail-safe
    }
}

// Usage in form validation
document.getElementById('submitBtn').addEventListener('click', async (e) => {
    e.preventDefault();
    const userInput = document.getElementById('commentField').value;
    
    if (await validateInput(userInput)) {
        document.getElementById('commentForm').submit();
    } else {
        showError('Your input contains potentially malicious content');
    }
});
```

## ğŸ§ª Testing Examples

### Safe Inputs (Should NOT be flagged)

```python
safe_inputs = [
    "Hello, how are you today?",
    "Welcome to our website! Feel free to explore.",
    "Check out this article: https://example.com/article",
    "My email is contact@example.com",
    "The price is $50 < $100 for premium users",
    "Use the formula: (x < 5) && (y > 10)",
    "I love <3 your product!",
    "Our store: Bed & Breakfast Inn",
    "Code snippet: if (x) { console.log('done'); }",
    "Rating: 4.5/5 stars â­â­â­â­"
]
```

### Basic Malicious Inputs (Should be flagged)

```python
basic_malicious = [
    "<script>alert('XSS')</script>",
    "<script>alert(1)</script>",
    "<img src=x onerror=alert(1)>",
    "<svg onload=alert(1)>",
    "javascript:alert(document.cookie)",
    "<iframe src='javascript:alert(1)'></iframe>",
    "<body onload=alert('XSS')>",
    "<input onfocus=alert(1) autofocus>",
    "<details open ontoggle=alert(1)>",
    "<object data='javascript:alert(1)'>"
]
```

### Obfuscated/Advanced Attacks (Should be flagged)

```python
advanced_malicious = [
    # Mixed case
    "<ScRiPt>alert(1)</ScRiPt>",
    "<ImG sRc=x oNeRrOr=alert(1)>",
    
    # HTML entity encoding
    "&#60;script&#62;alert(1)&#60;/script&#62;",
    "<img src=x onerror='&#97;&#108;&#101;&#114;&#116;(1)'>",
    
    # URL encoding
    "%3Cscript%3Ealert(1)%3C/script%3E",
    
    # Unicode encoding
    "<script>\\u0061lert(1)</script>",
    "<img src=x onerror=\\u0061\\u006c\\u0065\\u0072\\u0074(1)>",
    
    # Null byte injection
    "<scr\\x00ipt>alert(1)</scr\\x00ipt>",
    
    # Event handler variations
    "<svg><animate onbegin=alert(1) attributeName=x>",
    "<input onblur=alert(1) autofocus><input autofocus>",
    
    # JavaScript protocol variations
    "<a href='jaVasCript:alert(1)'>Click</a>",
    "<iframe src='jAvAsCrIpT:alert(1)'>",
    
    # Data protocol
    "<object data='data:text/html,<script>alert(1)</script>'>",
    "<iframe src='data:text/html,<script>alert(1)</script>'>",
    
    # Template literals
    "<img src=`x`onerror=`alert(1)`>",
    
    # Polyglot
    "jaVasCript:/*-/*`/*\\`/*'/*\"/**/(/* */oNcliCk=alert() )//"
]
```

## ğŸ“Š Model Performance

### Metrics on Test Set

| Metric | Score | Details |
|--------|-------|---------|
| **Accuracy** | 99.93% | Overall correctness |
| **Precision** | 100.00% | True positives / All positives |
| **Recall** | 99.85% | True positives / All actual malicious |
| **F1-Score** | 0.9993% | Harmonic mean of precision and recall |
| **AUC** | 0.9996 | Area under ROC curve |

## ğŸ”§ Troubleshooting

### Common Issues

#### 1. TensorFlow Installation Failed

**Problem:** `pip install tensorflow` fails

**Solutions:**
```bash
# Option 1: Use CPU-only version (smaller, faster install)
pip install tensorflow-cpu

# Option 2: Specific version
pip install tensorflow==2.13.0

# Option 3: Check Python version (must be 3.8-3.11)
python --version
```

#### 2. Model Not Loading

**Problem:** `Model files not found`

**Solution:**
```bash
# Train the model first
python xss_cnn_lstm_trainer.py

# Verify files exist
ls -lh xss_cnn_lstm_model.h5 tokenizer.pkl
```

#### 3. CORS Errors

**Problem:** Browser shows CORS error

**Solution:** Already configured in `app_cnn_lstm.py`:
```python
CORS(app, resources={r"/*": {"origins": "*"}})
```

For production, restrict origins:
```python
CORS(app, resources={r"/*": {"origins": ["https://yourdomain.com"]}})
```

### Getting Help

- ğŸ“§ **Email**: mohit@example.com
- ğŸ’¬ **Issues**: [GitHub Issues](https://github.com/IsMohit/A-Predictive-Approach-to-XSS-Detection-Using-ML-Algorithms/issues)
- ğŸ“š **Documentation**: See `/docs` folder

## ğŸ¤ Contributing

This project is currently under active development. Contributions are welcome!

### How to Contribute

1. **Fork the repository**
2. **Create a feature branch**
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. **Make your changes**
4. **Test thoroughly**
5. **Commit your changes**
   ```bash
   git commit -m "Add amazing feature"
   ```
6. **Push to branch**
   ```bash
   git push origin feature/amazing-feature
   ```
7. **Open a Pull Request**

### Areas for Contribution

- ğŸ› Bug fixes
- âœ¨ New features
- ğŸ“ Documentation improvements
- ğŸ§ª Additional test cases
- ğŸ¨ UI/UX enhancements
- ğŸš€ Performance optimizations
- ğŸŒ Multi-language support

### Code of Conduct

- Be respectful and inclusive
- Write clear, documented code
- Test before submitting
- Follow existing code style

### ğŸš§ In Progress
- [ ] Enhanced obfuscation detection
- [ ] Model optimization (TensorFlow Lite)
- [ ] Comprehensive test suite
- [ ] Docker containerization

## ğŸ“š References

1. OWASP XSS Prevention Cheat Sheet: https://cheatsheetseries.owasp.org/cheatsheets/Cross_Site_Scripting_Prevention_Cheat_Sheet.html
2. Understanding LSTM Networks: https://colah.github.io/posts/2015-08-Understanding-LSTMs/
3. CNN for Text Classification: https://arxiv.org/abs/1408.5882
4. Web Application Security Best Practices: https://owasp.org/www-project-top-ten/

## ğŸ“ Contact

**Project Maintainer:** Mohit

- GitHub: [@IsMohit](https://github.com/IsMohit)
- Email: your.email@example.com
- Project Link: [https://github.com/IsMohit/A-Predictive-Approach-to-XSS-Detection-Using-ML-Algorithms](https://github.com/IsMohit/A-Predictive-Approach-to-XSS-Detection-Using-ML-Algorithms)

---


<p align="center">
  <sub>Last updated: Dec 2025</sub>
</p>